{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-08-18T19:51:24.192037Z",
     "iopub.status.busy": "2025-08-18T19:51:24.191757Z",
     "iopub.status.idle": "2025-08-18T19:51:31.350638Z",
     "shell.execute_reply": "2025-08-18T19:51:31.349881Z",
     "shell.execute_reply.started": "2025-08-18T19:51:24.192019Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T19:51:31.352068Z",
     "iopub.status.busy": "2025-08-18T19:51:31.351823Z",
     "iopub.status.idle": "2025-08-18T19:51:31.356333Z",
     "shell.execute_reply": "2025-08-18T19:51:31.355681Z",
     "shell.execute_reply.started": "2025-08-18T19:51:31.352048Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers,models\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T20:02:24.629950Z",
     "iopub.status.busy": "2025-08-18T20:02:24.629602Z",
     "iopub.status.idle": "2025-08-18T20:02:57.850296Z",
     "shell.execute_reply": "2025-08-18T20:02:57.849592Z",
     "shell.execute_reply.started": "2025-08-18T20:02:24.629927Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "image_dir = \"/kaggle/input/global-land-cover-mapping-openearthmap/images/train\"\n",
    "label_dir = \"/kaggle/input/global-land-cover-mapping-openearthmap/label/train\"\n",
    "TARGET_SIZE = (128, 128)\n",
    "\n",
    "\n",
    "def map_9_to_4(lbl):\n",
    "    mapped = np.zeros_like(lbl)\n",
    "    mapped[np.isin(lbl, [1, 2])] = 1\n",
    "    mapped[np.isin(lbl, [3, 4])] = 2\n",
    "    mapped[np.isin(lbl, [5, 6, 7, 8])] = 3\n",
    "    return mapped\n",
    "\n",
    "\n",
    "image_files = sorted([f for f in os.listdir(image_dir) if f.endswith(\".tif\")])\n",
    "label_files = sorted([f for f in os.listdir(label_dir) if f.endswith(\".tif\")])\n",
    "\n",
    "X, Y = [], []\n",
    "\n",
    "for img_file, lbl_file in zip(image_files, label_files):\n",
    "    img_path = os.path.join(image_dir, img_file)\n",
    "    lbl_path = os.path.join(label_dir, lbl_file)\n",
    "    \n",
    "    # Load images\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    lbl = Image.open(lbl_path)\n",
    "    \n",
    "    # Resize\n",
    "    img = img.resize(TARGET_SIZE, Image.BILINEAR)\n",
    "    lbl = lbl.resize(TARGET_SIZE, Image.NEAREST)\n",
    "    \n",
    "    # Convert to arrays\n",
    "    img_arr = np.array(img, dtype=np.float32) / 255.0\n",
    "    lbl_arr = np.array(lbl, dtype=np.int32)\n",
    "    \n",
    "    # Map 9 classes → 4 classes\n",
    "    lbl_arr = map_9_to_4(lbl_arr)\n",
    "    \n",
    "    X.append(img_arr)\n",
    "    Y.append(lbl_arr)\n",
    "\n",
    "X = np.array(X, dtype=np.float32)  \n",
    "Y = np.array(Y, dtype=np.int32)    \n",
    "\n",
    "print(\"Images shape:\", X.shape)\n",
    "print(\"Labels shape:\", Y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T20:03:09.476167Z",
     "iopub.status.busy": "2025-08-18T20:03:09.475877Z",
     "iopub.status.idle": "2025-08-18T20:03:15.097467Z",
     "shell.execute_reply": "2025-08-18T20:03:15.096629Z",
     "shell.execute_reply.started": "2025-08-18T20:03:09.476147Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "image_dir_val = \"/kaggle/input/global-land-cover-mapping-openearthmap/images/val\"\n",
    "label_dir_val = \"/kaggle/input/global-land-cover-mapping-openearthmap/label/val\"\n",
    "\n",
    "\n",
    "TARGET_SIZE = (128, 128)\n",
    "\n",
    "# Get sorted lists so images and labels align\n",
    "image_files_val = sorted([f for f in os.listdir(image_dir_val) if f.endswith(\".tif\")])\n",
    "label_files_val = sorted([f for f in os.listdir(label_dir_val) if f.endswith(\".tif\")])\n",
    "\n",
    "X_val = []\n",
    "Y_val = []\n",
    "\n",
    "for img_file, lbl_file in zip(image_files_val, label_files_val):\n",
    "    img_path = os.path.join(image_dir_val, img_file)\n",
    "    lbl_path = os.path.join(label_dir_val, lbl_file)\n",
    "\n",
    "    \n",
    "    img = Image.open(img_path).convert(\"RGB\")  \n",
    "    lbl = Image.open(lbl_path)                 \n",
    "\n",
    "   \n",
    "    img = img.resize(TARGET_SIZE, Image.BILINEAR)\n",
    "    lbl = lbl.resize(TARGET_SIZE, Image.NEAREST)\n",
    "\n",
    "   \n",
    "    img_arr = np.array(img, dtype=np.float32) / 255.0  # normalize [0,1]\n",
    "    lbl_arr = np.array(lbl, dtype=np.int32) \n",
    "    \n",
    "    lbl_arr = map_9_to_4(lbl_arr)  \n",
    "\n",
    "    X_val.append(img_arr)\n",
    "    Y_val.append(lbl_arr)\n",
    "\n",
    "X_val = np.array(X_val, dtype=np.float32)   \n",
    "Y_val = np.array(Y_val, dtype=np.int32)    \n",
    "\n",
    "print(\"Image dataset shape:\", X_val.shape)\n",
    "print(\"Label dataset shape:\", Y_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T20:03:17.550313Z",
     "iopub.status.busy": "2025-08-18T20:03:17.549579Z",
     "iopub.status.idle": "2025-08-18T20:03:17.684642Z",
     "shell.execute_reply": "2025-08-18T20:03:17.683907Z",
     "shell.execute_reply.started": "2025-08-18T20:03:17.550285Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "num_classes = len(np.unique(Y)) \n",
    "print(\"Num classes:\", num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T20:03:21.047343Z",
     "iopub.status.busy": "2025-08-18T20:03:21.047028Z",
     "iopub.status.idle": "2025-08-18T20:03:21.438472Z",
     "shell.execute_reply": "2025-08-18T20:03:21.437854Z",
     "shell.execute_reply.started": "2025-08-18T20:03:21.047320Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def visualize_sample(idx):\n",
    "    plt.figure(figsize=(10,5))\n",
    "\n",
    "    # Input image\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.title(\"Input Image\")\n",
    "    plt.imshow(X[idx])\n",
    "\n",
    "    # Label mask\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.title(\"Mask\")\n",
    "    plt.imshow(Y[idx].squeeze(),cmap='tab20')  \n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "# Example: visualize the 3rd image–mask pair\n",
    "visualize_sample(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T20:04:30.189353Z",
     "iopub.status.busy": "2025-08-18T20:04:30.189016Z",
     "iopub.status.idle": "2025-08-18T20:04:30.346125Z",
     "shell.execute_reply": "2025-08-18T20:04:30.345571Z",
     "shell.execute_reply.started": "2025-08-18T20:04:30.189329Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def unet(input_shape=(128,128,3), num_classes=4):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # --- Encoder ---\n",
    "    conv1 = layers.Conv2D(64, 3, padding='same', activation='relu')(inputs)\n",
    "    conv1 = layers.Conv2D(64, 3, padding='same', activation='relu')(conv1)\n",
    "    pool1 = layers.MaxPooling2D(pool_size=(2,2))(conv1)\n",
    "    \n",
    "    conv2 = layers.Conv2D(128, 3, padding='same', activation='relu')(pool1)\n",
    "    conv2 = layers.Conv2D(128, 3, padding='same', activation='relu')(conv2)\n",
    "    pool2 = layers.MaxPooling2D(pool_size=(2,2))(conv2)\n",
    "    \n",
    "    conv3 = layers.Conv2D(256, 3, padding='same', activation='relu')(pool2)\n",
    "    conv3 = layers.Conv2D(256, 3, padding='same', activation='relu')(conv3)\n",
    "    pool3 = layers.MaxPooling2D(pool_size=(2,2))(conv3)\n",
    "    \n",
    "    # --- Bridge ---\n",
    "    conv4 = layers.Conv2D(512, 3, padding='same', activation='relu')(pool3)\n",
    "    conv4 = layers.Conv2D(512, 3, padding='same', activation='relu')(conv4)\n",
    "    drop4 = layers.Dropout(0.5)(conv4)\n",
    "    \n",
    "    # --- Decoder ---\n",
    "    up5 = layers.Conv2DTranspose(256, 2, strides=(2,2), padding='same')(drop4)\n",
    "    merge5 = layers.concatenate([conv3, up5], axis=3)\n",
    "    conv5 = layers.Conv2D(256, 3, padding='same', activation='relu')(merge5)\n",
    "    conv5 = layers.Conv2D(256, 3, padding='same', activation='relu')(conv5)\n",
    "    \n",
    "    up6 = layers.Conv2DTranspose(128, 2, strides=(2,2), padding='same')(conv5)\n",
    "    merge6 = layers.concatenate([conv2, up6], axis=3)\n",
    "    conv6 = layers.Conv2D(128, 3, padding='same', activation='relu')(merge6)\n",
    "    conv6 = layers.Conv2D(128, 3, padding='same', activation='relu')(conv6)\n",
    "    \n",
    "    up7 = layers.Conv2DTranspose(64, 2, strides=(2,2), padding='same')(conv6)\n",
    "    merge7 = layers.concatenate([conv1, up7], axis=3)\n",
    "    conv7 = layers.Conv2D(64, 3, padding='same', activation='relu')(merge7)\n",
    "    conv7 = layers.Conv2D(64, 3, padding='same', activation='relu')(conv7)\n",
    "    \n",
    "    # --- Output ---\n",
    "    outputs = layers.Conv2D(num_classes, 1, activation='softmax')(conv7)\n",
    "    \n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "model = unet()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-08-18T20:04:50.869204Z",
     "iopub.status.busy": "2025-08-18T20:04:50.868673Z",
     "iopub.status.idle": "2025-08-18T20:44:13.581082Z",
     "shell.execute_reply": "2025-08-18T20:44:13.580411Z",
     "shell.execute_reply.started": "2025-08-18T20:04:50.869179Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import numpy as np\n",
    "\n",
    "num_classes = 4  \n",
    "\n",
    "\n",
    "class SparseMeanIoU(tf.keras.metrics.Metric):\n",
    "    def __init__(self, num_classes=num_classes, name=\"mean_iou\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.num_classes = num_classes\n",
    "        self.mean_iou_metric = tf.keras.metrics.MeanIoU(num_classes=num_classes)\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_pred_classes = tf.argmax(y_pred, axis=-1)  \n",
    "        self.mean_iou_metric.update_state(y_true, y_pred_classes, sample_weight)\n",
    "\n",
    "    def result(self):\n",
    "        return self.mean_iou_metric.result()\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.mean_iou_metric.reset_state()\n",
    "\n",
    "\n",
    "class_weights = np.ones(num_classes)  \n",
    "\n",
    "def multiclass_dice(y_true, y_pred, num_classes=num_classes, smooth=1e-6):\n",
    "    y_true = tf.cast(y_true, tf.int32)\n",
    "    y_true_onehot = tf.one_hot(y_true, depth=num_classes, dtype=tf.float32)\n",
    "    y_pred_prob = tf.nn.softmax(y_pred, axis=-1)\n",
    "    y_true_f = tf.reshape(y_true_onehot, [-1, num_classes])\n",
    "    y_pred_f = tf.reshape(y_pred_prob, [-1, num_classes])\n",
    "    intersection = tf.reduce_sum(y_true_f * y_pred_f, axis=0)\n",
    "    union = tf.reduce_sum(y_true_f + y_pred_f, axis=0)\n",
    "    dice_per_class = (2. * intersection + smooth) / (union + smooth)\n",
    "    return tf.reduce_mean(dice_per_class)\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    return 1 - multiclass_dice(y_true, y_pred)\n",
    "\n",
    "def focal_loss(y_true, y_pred, alpha=0.25, gamma=2.0):\n",
    "    y_true = tf.cast(y_true, tf.int32)\n",
    "    y_true_onehot = tf.one_hot(y_true, depth=num_classes, dtype=tf.float32)\n",
    "    y_pred_prob = tf.nn.softmax(y_pred, axis=-1)\n",
    "    y_pred_prob = tf.clip_by_value(y_pred_prob, 1e-8, 1-1e-8)\n",
    "    \n",
    "    ce_loss = -y_true_onehot * tf.math.log(y_pred_prob)\n",
    "    pt = tf.where(tf.equal(y_true_onehot, 1), y_pred_prob, 1 - y_pred_prob)\n",
    "    focal_weight = alpha * tf.pow(1 - pt, gamma) * class_weights\n",
    "    focal_loss_val = focal_weight * ce_loss\n",
    "    return tf.reduce_mean(tf.reduce_sum(focal_loss_val, axis=-1))\n",
    "\n",
    "def combined_loss(y_true, y_pred):\n",
    "    return 0.5 * dice_loss(y_true, y_pred) + 0.5 * focal_loss(y_true, y_pred)\n",
    "\n",
    "\n",
    "def sparse_categorical_accuracy_custom(y_true, y_pred):\n",
    "    y_pred_classes = tf.argmax(y_pred, axis=-1)\n",
    "    return tf.reduce_mean(tf.cast(tf.equal(tf.cast(y_true, tf.int64), y_pred_classes), tf.float32))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(1e-4),\n",
    "    loss=combined_loss,\n",
    "    metrics=[sparse_categorical_accuracy_custom, SparseMeanIoU(num_classes=num_classes)]\n",
    ")\n",
    "\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        \"sat_map_seg_best.h5\",\n",
    "        monitor=\"val_mean_iou\",\n",
    "        mode=\"max\",\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    EarlyStopping(\n",
    "        patience=12,\n",
    "        monitor=\"val_mean_iou\",\n",
    "        mode=\"max\",\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        factor=0.5,\n",
    "        patience=4,\n",
    "        monitor=\"val_mean_iou\",\n",
    "        mode=\"max\",\n",
    "        min_lr=1e-6,\n",
    "        verbose=1,\n",
    "        cooldown=1\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    X, Y,  # X, Y are your training images and labels\n",
    "    validation_data=(X_val, Y_val),\n",
    "    epochs=100,\n",
    "    batch_size=8,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1,\n",
    "    shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T20:46:26.297872Z",
     "iopub.status.busy": "2025-08-18T20:46:26.297086Z",
     "iopub.status.idle": "2025-08-18T20:46:27.239135Z",
     "shell.execute_reply": "2025-08-18T20:46:27.238450Z",
     "shell.execute_reply.started": "2025-08-18T20:46:26.297845Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "idx = 99\n",
    "test_img = X_val[idx]  # shape: (H, W, 3)\n",
    "test_mask = Y_val[idx] # shape: (H, W)\n",
    "\n",
    "# Add batch dimension\n",
    "input_img = np.expand_dims(test_img, axis=0)  # shape: (1, H, W, 3)\n",
    "\n",
    "# Predict mask probabilities for all classes\n",
    "pred_mask_prob_full = model.predict(input_img)[0]  # shape: (H, W, 9)\n",
    "\n",
    "print(\"Predicted mask shape:\", pred_mask_prob_full.shape)\n",
    "print(\"Min prob:\", pred_mask_prob_full.min())\n",
    "print(\"Max prob:\", pred_mask_prob_full.max())\n",
    "\n",
    "# Convert probabilities to predicted class\n",
    "pred_mask = np.argmax(pred_mask_prob_full, axis=-1)  # shape: (H, W), values 0..8\n",
    "\n",
    "# Plot input image, true mask, predicted mask\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(test_img)\n",
    "plt.title(\"Input Image\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(test_mask, cmap='tab20')\n",
    "plt.title(\"Ground Truth Mask\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(pred_mask, cmap='tab20')\n",
    "plt.title(\"Predicted Mask\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4933374,
     "sourceId": 8304744,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
