{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8304744,"sourceType":"datasetVersion","datasetId":4933374}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-18T19:51:24.191757Z","iopub.execute_input":"2025-08-18T19:51:24.192037Z","iopub.status.idle":"2025-08-18T19:51:31.350638Z","shell.execute_reply.started":"2025-08-18T19:51:24.192019Z","shell.execute_reply":"2025-08-18T19:51:31.349881Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from PIL import Image\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers,models\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T19:51:31.351823Z","iopub.execute_input":"2025-08-18T19:51:31.352068Z","iopub.status.idle":"2025-08-18T19:51:31.356333Z","shell.execute_reply.started":"2025-08-18T19:51:31.352048Z","shell.execute_reply":"2025-08-18T19:51:31.355681Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nfrom PIL import Image\n\n# -----------------------------\n# Directories\n# -----------------------------\nimage_dir = \"/kaggle/input/global-land-cover-mapping-openearthmap/images/train\"\nlabel_dir = \"/kaggle/input/global-land-cover-mapping-openearthmap/label/train\"\nTARGET_SIZE = (128, 128)\n\n# -----------------------------\n# Class Mapping: 9 → 4\n# Example mapping (adjust to your classes):\n# 0 → 0 (background)\n# 1,2 → 1\n# 3,4 → 2\n# 5,6,7,8 → 3\n# -----------------------------\ndef map_9_to_4(lbl):\n    mapped = np.zeros_like(lbl)\n    mapped[np.isin(lbl, [1, 2])] = 1\n    mapped[np.isin(lbl, [3, 4])] = 2\n    mapped[np.isin(lbl, [5, 6, 7, 8])] = 3\n    return mapped\n\n# -----------------------------\n# Load Dataset\n# -----------------------------\nimage_files = sorted([f for f in os.listdir(image_dir) if f.endswith(\".tif\")])\nlabel_files = sorted([f for f in os.listdir(label_dir) if f.endswith(\".tif\")])\n\nX, Y = [], []\n\nfor img_file, lbl_file in zip(image_files, label_files):\n    img_path = os.path.join(image_dir, img_file)\n    lbl_path = os.path.join(label_dir, lbl_file)\n    \n    # Load images\n    img = Image.open(img_path).convert(\"RGB\")\n    lbl = Image.open(lbl_path)\n    \n    # Resize\n    img = img.resize(TARGET_SIZE, Image.BILINEAR)\n    lbl = lbl.resize(TARGET_SIZE, Image.NEAREST)\n    \n    # Convert to arrays\n    img_arr = np.array(img, dtype=np.float32) / 255.0\n    lbl_arr = np.array(lbl, dtype=np.int32)\n    \n    # Map 9 classes → 4 classes\n    lbl_arr = map_9_to_4(lbl_arr)\n    \n    X.append(img_arr)\n    Y.append(lbl_arr)\n\nX = np.array(X, dtype=np.float32)  # (N, H, W, 3)\nY = np.array(Y, dtype=np.int32)    # (N, H, W)\n\nprint(\"Images shape:\", X.shape)\nprint(\"Labels shape:\", Y.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T20:02:24.629602Z","iopub.execute_input":"2025-08-18T20:02:24.629950Z","iopub.status.idle":"2025-08-18T20:02:57.850296Z","shell.execute_reply.started":"2025-08-18T20:02:24.629927Z","shell.execute_reply":"2025-08-18T20:02:57.849592Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image_dir_val = \"/kaggle/input/global-land-cover-mapping-openearthmap/images/val\"\nlabel_dir_val = \"/kaggle/input/global-land-cover-mapping-openearthmap/label/val\"\n\n\nTARGET_SIZE = (128, 128)\n\n# Get sorted lists so images and labels align\nimage_files_val = sorted([f for f in os.listdir(image_dir_val) if f.endswith(\".tif\")])\nlabel_files_val = sorted([f for f in os.listdir(label_dir_val) if f.endswith(\".tif\")])\n\nX_val = []\nY_val = []\n\nfor img_file, lbl_file in zip(image_files_val, label_files_val):\n    img_path = os.path.join(image_dir_val, img_file)\n    lbl_path = os.path.join(label_dir_val, lbl_file)\n\n    \n    img = Image.open(img_path).convert(\"RGB\")  # Ensure 3 channels\n    lbl = Image.open(lbl_path)                 # Mask can stay single channel\n\n   \n    img = img.resize(TARGET_SIZE, Image.BILINEAR)\n    lbl = lbl.resize(TARGET_SIZE, Image.NEAREST)\n\n   \n    img_arr = np.array(img, dtype=np.float32) / 255.0  # normalize [0,1]\n    lbl_arr = np.array(lbl, dtype=np.int32) \n    \n    lbl_arr = map_9_to_4(lbl_arr)  \n\n    X_val.append(img_arr)\n    Y_val.append(lbl_arr)\n\nX_val = np.array(X_val, dtype=np.float32)   # (N, H, W, 3)\nY_val = np.array(Y_val, dtype=np.int32)    \n\nprint(\"Image dataset shape:\", X_val.shape)\nprint(\"Label dataset shape:\", Y_val.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T20:03:09.475877Z","iopub.execute_input":"2025-08-18T20:03:09.476167Z","iopub.status.idle":"2025-08-18T20:03:15.097467Z","shell.execute_reply.started":"2025-08-18T20:03:09.476147Z","shell.execute_reply":"2025-08-18T20:03:15.096629Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_classes = len(np.unique(Y)) \nprint(\"Num classes:\", num_classes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T20:03:17.549579Z","iopub.execute_input":"2025-08-18T20:03:17.550313Z","iopub.status.idle":"2025-08-18T20:03:17.684642Z","shell.execute_reply.started":"2025-08-18T20:03:17.550285Z","shell.execute_reply":"2025-08-18T20:03:17.683907Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def visualize_sample(idx):\n    plt.figure(figsize=(10,5))\n\n    # Input image\n    plt.subplot(1,2,1)\n    plt.title(\"Input Image\")\n    plt.imshow(X[idx])\n\n    # Label mask\n    plt.subplot(1,2,2)\n    plt.title(\"Mask\")\n    plt.imshow(Y[idx].squeeze(),cmap='tab20')  # 'jet' shows classes with colors\n    plt.colorbar()\n    plt.show()\n\n# Example: visualize the 3rd image–mask pair\nvisualize_sample(3)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T20:03:21.047028Z","iopub.execute_input":"2025-08-18T20:03:21.047343Z","iopub.status.idle":"2025-08-18T20:03:21.438472Z","shell.execute_reply.started":"2025-08-18T20:03:21.047320Z","shell.execute_reply":"2025-08-18T20:03:21.437854Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models\n\ndef unet(input_shape=(128,128,3), num_classes=4):\n    inputs = layers.Input(shape=input_shape)\n    \n    # --- Encoder ---\n    conv1 = layers.Conv2D(64, 3, padding='same', activation='relu')(inputs)\n    conv1 = layers.Conv2D(64, 3, padding='same', activation='relu')(conv1)\n    pool1 = layers.MaxPooling2D(pool_size=(2,2))(conv1)\n    \n    conv2 = layers.Conv2D(128, 3, padding='same', activation='relu')(pool1)\n    conv2 = layers.Conv2D(128, 3, padding='same', activation='relu')(conv2)\n    pool2 = layers.MaxPooling2D(pool_size=(2,2))(conv2)\n    \n    conv3 = layers.Conv2D(256, 3, padding='same', activation='relu')(pool2)\n    conv3 = layers.Conv2D(256, 3, padding='same', activation='relu')(conv3)\n    pool3 = layers.MaxPooling2D(pool_size=(2,2))(conv3)\n    \n    # --- Bridge ---\n    conv4 = layers.Conv2D(512, 3, padding='same', activation='relu')(pool3)\n    conv4 = layers.Conv2D(512, 3, padding='same', activation='relu')(conv4)\n    drop4 = layers.Dropout(0.5)(conv4)\n    \n    # --- Decoder ---\n    up5 = layers.Conv2DTranspose(256, 2, strides=(2,2), padding='same')(drop4)\n    merge5 = layers.concatenate([conv3, up5], axis=3)\n    conv5 = layers.Conv2D(256, 3, padding='same', activation='relu')(merge5)\n    conv5 = layers.Conv2D(256, 3, padding='same', activation='relu')(conv5)\n    \n    up6 = layers.Conv2DTranspose(128, 2, strides=(2,2), padding='same')(conv5)\n    merge6 = layers.concatenate([conv2, up6], axis=3)\n    conv6 = layers.Conv2D(128, 3, padding='same', activation='relu')(merge6)\n    conv6 = layers.Conv2D(128, 3, padding='same', activation='relu')(conv6)\n    \n    up7 = layers.Conv2DTranspose(64, 2, strides=(2,2), padding='same')(conv6)\n    merge7 = layers.concatenate([conv1, up7], axis=3)\n    conv7 = layers.Conv2D(64, 3, padding='same', activation='relu')(merge7)\n    conv7 = layers.Conv2D(64, 3, padding='same', activation='relu')(conv7)\n    \n    # --- Output ---\n    outputs = layers.Conv2D(num_classes, 1, activation='softmax')(conv7)\n    \n    model = models.Model(inputs=inputs, outputs=outputs)\n    return model\n\n# Example usage\nmodel = unet()\nmodel.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T20:04:30.189016Z","iopub.execute_input":"2025-08-18T20:04:30.189353Z","iopub.status.idle":"2025-08-18T20:04:30.346125Z","shell.execute_reply.started":"2025-08-18T20:04:30.189329Z","shell.execute_reply":"2025-08-18T20:04:30.345571Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nimport numpy as np\n\nnum_classes = 4  # Your 4 classes\n\n# -----------------------------\n# Custom Mean IoU Metric for Sparse Labels\n# -----------------------------\nclass SparseMeanIoU(tf.keras.metrics.Metric):\n    def __init__(self, num_classes=num_classes, name=\"mean_iou\", **kwargs):\n        super().__init__(name=name, **kwargs)\n        self.num_classes = num_classes\n        self.mean_iou_metric = tf.keras.metrics.MeanIoU(num_classes=num_classes)\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        y_pred_classes = tf.argmax(y_pred, axis=-1)  # Convert predictions to class indices\n        self.mean_iou_metric.update_state(y_true, y_pred_classes, sample_weight)\n\n    def result(self):\n        return self.mean_iou_metric.result()\n\n    def reset_state(self):\n        self.mean_iou_metric.reset_state()\n\n# -----------------------------\n# Combined Dice + Focal Loss\n# -----------------------------\nclass_weights = np.ones(num_classes)  # Can adjust if some classes are rare\n\ndef multiclass_dice(y_true, y_pred, num_classes=num_classes, smooth=1e-6):\n    y_true = tf.cast(y_true, tf.int32)\n    y_true_onehot = tf.one_hot(y_true, depth=num_classes, dtype=tf.float32)\n    y_pred_prob = tf.nn.softmax(y_pred, axis=-1)\n    y_true_f = tf.reshape(y_true_onehot, [-1, num_classes])\n    y_pred_f = tf.reshape(y_pred_prob, [-1, num_classes])\n    intersection = tf.reduce_sum(y_true_f * y_pred_f, axis=0)\n    union = tf.reduce_sum(y_true_f + y_pred_f, axis=0)\n    dice_per_class = (2. * intersection + smooth) / (union + smooth)\n    return tf.reduce_mean(dice_per_class)\n\ndef dice_loss(y_true, y_pred):\n    return 1 - multiclass_dice(y_true, y_pred)\n\ndef focal_loss(y_true, y_pred, alpha=0.25, gamma=2.0):\n    y_true = tf.cast(y_true, tf.int32)\n    y_true_onehot = tf.one_hot(y_true, depth=num_classes, dtype=tf.float32)\n    y_pred_prob = tf.nn.softmax(y_pred, axis=-1)\n    y_pred_prob = tf.clip_by_value(y_pred_prob, 1e-8, 1-1e-8)\n    \n    ce_loss = -y_true_onehot * tf.math.log(y_pred_prob)\n    pt = tf.where(tf.equal(y_true_onehot, 1), y_pred_prob, 1 - y_pred_prob)\n    focal_weight = alpha * tf.pow(1 - pt, gamma) * class_weights\n    focal_loss_val = focal_weight * ce_loss\n    return tf.reduce_mean(tf.reduce_sum(focal_loss_val, axis=-1))\n\ndef combined_loss(y_true, y_pred):\n    return 0.5 * dice_loss(y_true, y_pred) + 0.5 * focal_loss(y_true, y_pred)\n\n# -----------------------------\n# Sparse Categorical Accuracy\n# -----------------------------\ndef sparse_categorical_accuracy_custom(y_true, y_pred):\n    y_pred_classes = tf.argmax(y_pred, axis=-1)\n    return tf.reduce_mean(tf.cast(tf.equal(tf.cast(y_true, tf.int64), y_pred_classes), tf.float32))\n\n\n\n# -----------------------------\n# Compile Model\n# -----------------------------\nmodel.compile(\n    optimizer=Adam(1e-4),\n    loss=combined_loss,\n    metrics=[sparse_categorical_accuracy_custom, SparseMeanIoU(num_classes=num_classes)]\n)\n\n# -----------------------------\n# Callbacks\n# -----------------------------\ncallbacks = [\n    ModelCheckpoint(\n        \"sat_map_seg_best.h5\",\n        monitor=\"val_mean_iou\",\n        mode=\"max\",\n        save_best_only=True,\n        verbose=1\n    ),\n    EarlyStopping(\n        patience=12,\n        monitor=\"val_mean_iou\",\n        mode=\"max\",\n        restore_best_weights=True,\n        verbose=1\n    ),\n    ReduceLROnPlateau(\n        factor=0.5,\n        patience=4,\n        monitor=\"val_mean_iou\",\n        mode=\"max\",\n        min_lr=1e-6,\n        verbose=1,\n        cooldown=1\n    )\n]\n\n# -----------------------------\n# Train the Model\n# -----------------------------\nhistory = model.fit(\n    X, Y,  # X, Y are your training images and labels\n    validation_data=(X_val, Y_val),\n    epochs=100,\n    batch_size=8,\n    callbacks=callbacks,\n    verbose=1,\n    shuffle=True\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T20:04:50.868673Z","iopub.execute_input":"2025-08-18T20:04:50.869204Z","iopub.status.idle":"2025-08-18T20:44:13.581082Z","shell.execute_reply.started":"2025-08-18T20:04:50.869179Z","shell.execute_reply":"2025-08-18T20:44:13.580411Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"idx = 99\ntest_img = X_val[idx]  # shape: (H, W, 3)\ntest_mask = Y_val[idx] # shape: (H, W)\n\n# Add batch dimension\ninput_img = np.expand_dims(test_img, axis=0)  # shape: (1, H, W, 3)\n\n# Predict mask probabilities for all classes\npred_mask_prob_full = model.predict(input_img)[0]  # shape: (H, W, 9)\n\nprint(\"Predicted mask shape:\", pred_mask_prob_full.shape)\nprint(\"Min prob:\", pred_mask_prob_full.min())\nprint(\"Max prob:\", pred_mask_prob_full.max())\n\n# Convert probabilities to predicted class\npred_mask = np.argmax(pred_mask_prob_full, axis=-1)  # shape: (H, W), values 0..8\n\n# Plot input image, true mask, predicted mask\nplt.figure(figsize=(12, 4))\n\nplt.subplot(1, 3, 1)\nplt.imshow(test_img)\nplt.title(\"Input Image\")\nplt.axis('off')\n\nplt.subplot(1, 3, 2)\nplt.imshow(test_mask, cmap='tab20')\nplt.title(\"Ground Truth Mask\")\nplt.axis('off')\n\nplt.subplot(1, 3, 3)\nplt.imshow(pred_mask, cmap='tab20')\nplt.title(\"Predicted Mask\")\nplt.axis('off')\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T20:46:26.297086Z","iopub.execute_input":"2025-08-18T20:46:26.297872Z","iopub.status.idle":"2025-08-18T20:46:27.239135Z","shell.execute_reply.started":"2025-08-18T20:46:26.297845Z","shell.execute_reply":"2025-08-18T20:46:27.238450Z"}},"outputs":[],"execution_count":null}]}